ğŸšªâœ¨ Dharma Dwar
ğŸ§  Visionâ€“Voice Based Smart Door Access System (Offline AI)

Dharma Dwar is an offline smart door access system that uses hand-gesture recognition âœ‹ and speech recognition ğŸ™ï¸ as a two-factor authentication mechanism.
The door opens only when:

A closed fist is detected âœŠ

The user speaks â€œopen the doorâ€ ğŸ—£ï¸

After opening, the door automatically closes after 5 seconds â±ï¸.

ğŸ”’ No internet
ğŸ”‘ No API keys
â˜ï¸ No cloud services
ğŸ§© Works on low-resource devices like Raspberry Pi Zero 2 W

ğŸ§© System Architecture (High Level)

ğŸ“· Camera â†’ Hand Gesture Detection
ğŸ¤ Microphone â†’ Speech-to-Text
ğŸ§  Decision Logic â†’ Two-Factor Authentication
ğŸšª Door Control â†’ Open â†’ Auto-Close

âœ‹ Hand Gesture Recognition Module

Built using MediaPipe Hands ğŸ–ï¸ and OpenCV ğŸ‘ï¸

Detects 21 hand landmarks per frame

Compares:

Finger tips vs PIP joints

Gesture classification:

ğŸŸ¢ OPEN HAND (4+ fingers extended)

ğŸ”´ CLOSED FIST (fingers folded)

ğŸ“¦ Real-time bounding box + label displayed on video feed

Gesture status is continuously tracked and shared with the voice module.

ğŸ™ï¸ Speech-to-Text Module (Offline)

Powered by Vosk (Offline STT Engine)

Uses SoundDevice for real-time audio capture

Audio format:

16-bit PCM

16 kHz sample rate

Recognizes speech locally (no internet required)

ğŸ“ Last recognized command shown on screen

This ensures privacy, reliability, and low latency.

ğŸ” Authentication & Decision Logic

Access is granted only when BOTH conditions are true:

âœ”ï¸ Gesture = CLOSED FIST
âœ”ï¸ Voice command = â€œopen the doorâ€

âŒ Voice without gesture â†’ Access denied
âŒ Gesture without voice â†’ Ignored

Thread-safe logic prevents repeated or accidental triggers.

â±ï¸ Door Control & Timing Logic

Prints ğŸšª OPENING DOOR

Starts a 5-second timer

Automatically prints ğŸ”’ CLOSING DOOR

ğŸ§ª Currently simulated using print()
âš™ï¸ Easily extendable to:

Servo motors

Solenoid locks

Relay modules via GPIO

ğŸ§µ Concurrency & Performance

Multi-threaded design

Main thread â†’ Camera + gesture detection

Background thread â†’ Speech recognition

Prevents audio blocking video

Runs smoothly on constrained hardware

ğŸ“¦ Required Hardware
Component	Purpose
ğŸ“· USB Camera	Hand detection
ğŸ¤ USB Microphone	Voice input
ğŸ’» Raspberry Pi / PC	Processing
ğŸ”Œ Power Supply	Stable operation

(Servo/lock optional for future upgrades)

ğŸ“š Required Software & Libraries
ğŸ Python Version

Python 3.9 â€“ 3.11 recommended

ğŸ“¦ Python Libraries

Install all dependencies using:

pip install opencv-python mediapipe numpy sounddevice vosk

ğŸ“Œ Library Purpose
Library	Use
opencv-python -------------	Camera & image processing
mediapipe	------------- Hand landmark detection
numpy	------------- Math & array operations
sounddevice	------------- Microphone audio stream
vosk -------------	Offline speech recognition
json -------------	STT result parsing
threading -------------	Multi-threading
queue -------------	Audio buffering

ğŸ“¥ Download Vosk Model

Download a small English model:

ğŸ”— https://alphacephei.com/vosk/models

Recommended:

vosk-model-small-en-us-0.15


Place it inside:

models/
â””â”€â”€ vosk-model-small-en-us-0.15/

â–¶ï¸ How to Run (Beginner Steps)
git clone https://github.com/yourusername/dharma-dwar.git
cd dharma-dwar
python main.py


ğŸ–ï¸ Show a closed fist
ğŸ—£ï¸ Say â€œopen the doorâ€
ğŸšª Watch the system respond

Press ESC to exit.

ğŸŒŸ Key Features

âœ… Fully offline AI
âœ… Gesture + voice security
âœ… Real-time visual feedback
âœ… Low RAM & CPU usage
âœ… Modular & extendable
âœ… Beginner-friendly code

ğŸš€ Applications & Future Scope

ğŸ  Smart Homes
ğŸ” Secure Rooms
ğŸ¤– Robotics
â™¿ Assistive Tech
ğŸ§ª AI Research

ğŸ”® Future Enhancements:

ğŸ‘¤ Face recognition

ğŸ”Š Voice feedback

ğŸ“± Mobile dashboard

ğŸ” Encrypted user profiles

âš™ï¸ Servo / lock integration

ğŸ§  Final Note

This is not a toy project.
It is a proper embedded AI access-control system following real-world humanâ€“machine interaction principles â€” scaled intelligently for learning and experimentation.
